{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e55bdcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\ccaas\\anaconda3\\lib\\site-packages (4.27.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\ccaas\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in c:\\users\\ccaas\\anaconda3\\lib\\site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ccaas\\anaconda3\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ccaas\\anaconda3\\lib\\site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ccaas\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ccaas\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\ccaas\\anaconda3\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\ccaas\\anaconda3\\lib\\site-packages (from transformers) (0.13.4rc1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ccaas\\anaconda3\\lib\\site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ccaas\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.12.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ccaas\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ccaas\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ccaas\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ccaas\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ccaas\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ccaas\\anaconda3\\lib\\site-packages (from requests->transformers) (2023.7.22)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15842b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer,GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1281fe3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c3e2a2f55484f7eac426363bfbf4660",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ccaas\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\ccaas\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "162e3912c5794cda8416a418f5897379",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1def2eda2214c28be489753f31bbdba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/666 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer=GPT2Tokenizer.from_pretrained('gpt2-large')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d983e4fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de32db5adc449b9ac34f7c8e05c6c0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.25G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dc55520df9a44bdbe2d6303164d1c33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model=GPT2LMHeadModel.from_pretrained('gpt2-large',pad_token_id=tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7ccec0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50256"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token_id # return the vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfebeb54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7f7a996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   40,  1842,  4964, 49066,  6918]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence=\"I love watching motivational movies\"\n",
    "numeric_ids=tokenizer.encode(sentence,return_tensors='pt')\n",
    "numeric_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f3b69c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' movies'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(numeric_ids[0][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2025ebf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   40,  1842,  4964, 49066,  6918,    11,   290,   428,   530,   318,\n",
       "           530,   286,   616, 18852,    13,   632,   338,   546,   257,  3516,\n",
       "           508,   338,  2111,   284,  4425,  3463,    11,   475,   339,   460,\n",
       "           470,  1283,   284,   466,   340,    13,  1406,   339,  2925,   284,\n",
       "           257,  3463,  2994, 15760,    11,   810,   339, 11185,   257,  2415,\n",
       "           508,  1139,   673,   460,  1037,   683,  4425,   262,  3463,    13,\n",
       "           198,   198,   464,  3807,  5645,   351,   262,  2415,  5149,   262,\n",
       "          3516,   326,   339,   338,   407,  1016,   284,   307,  1498,   284,\n",
       "          1394,   465,  3463,   572,  8097,    13,  1375,  4952,   683,   326,\n",
       "           611,   339,  3382,   284,   651,  5448,    11,   339,  1183,   423,\n",
       "           284,  1487,   465,  6600, 13870,    13,   383,  3516,  1139,    11,\n",
       "           366,    40,   836,   470,   760,   644,   345,   821,  3375,   546,\n",
       "            13,   314,  1101,   407,  6600, 18556,  2057,   526,   383,  2415,\n",
       "           788,  1139,   326,   673,  1183,   905,   683,   703,   284,  4483,\n",
       "          5448,   290,   651,  5755,   286,   477,   262, 18556,   287,   465,\n",
       "          1204,    13,   679,  1139,   339,  1595,   470,   765,   284,  6004,\n",
       "           284,   607,    11,   523,   673, 11114,  1497,   290,  5667,   683,\n",
       "           284,   465,   898,  4410,    13,  1320,   338,   262,   886,   286,\n",
       "           262,  3807,    11,   826,    30,  3894,    11,   407,   523,  3049,\n",
       "            13,  1318,   338,   257,  1256,   517,  1016,   319,   287,   428,\n",
       "          3807,   621, 11185,   262,  4151,    13,  3914,   338,  1011,   257,\n",
       "          5699,   804,   379,   644,   338,  5836,   287,   262,  2646,    13,\n",
       "           628,   198,  5962,    11,  1309,   338,  1561,   546,   262,   366,\n",
       "            73,  2954,  2057,     1,   636,   286,   428,  1621,    13, 34980,\n",
       "          2057,   318,  2057,   326,   338,  1029,   287, 14653,   290,  1877,\n",
       "           287, 20901,    13,  1114,  1672,    11,   257,  6131,   286,  2580,\n",
       "           316,   418,   318,   257,  1029,    12,  9948, 19257, 26906,    13,\n",
       "           887,   340,   338,   635,   257,  1877,    12, 14930,  8289, 26906,\n",
       "            11,   780,   340,  4909,   645, 29091,    11, 21622,    11,   393,\n",
       "         13608,    13,   554,  1109,    11,   262,   691,  1517,   340,   468,\n",
       "           287,  2219,   351,   257,  5448, 26906,   318,   326,   340,  2058,\n",
       "           287,   257,  7309,  6131,    13,  1002,   345,  4483,   340,    11,\n",
       "           345,  1183,   886,   510,   351,   517, 14653,   621,   345,  2067,\n",
       "           351,    11,   543,  1724,   326,   345,  1839,   470,   307,  1972,\n",
       "           262, 20901,   345,   761,   284,  2652,  5448,    13,   770,   318,\n",
       "          1521, 18556,  9013,   389,   523,  2089,   329,   534,  1535,    13,\n",
       "          1119,   821,   407,   922,   329,   345,    11,   484,   821, 13568,\n",
       "           284,   534,  1767,   290,   345,   815,  3368,   606,   379,   477,\n",
       "          3484,    13,   921,   460,  1100,   517,   546,   428,   287,   616,\n",
       "          2708,   319, 34980,  7318,   290, 14331, 22014,    13,  3423,   338,\n",
       "          1194,   835,   284,   892,   546,   340,    25,   611,   345, 15063,\n",
       "           262,   976,  2033,   286,  2057,   790,  1110,    11,   340,   561,\n",
       "          1011,   345,   257,   890,   640,   284,  4245,   572,   477,   286,\n",
       "           326,  2057,    13,  3406,  1767,   561,   423,   257,  1327,   640,\n",
       "          9482,   340,   477,   572,    11,   772,   996,   345,  1549,   423,\n",
       "          6088,   286,  2568,  1364,   625,   329,   584,  1243,    11,   588,\n",
       "         25352,   290,  6600,   517,  5448,  9013,   588, 15921,    11, 13701,\n",
       "            11,  2187, 21824,    11,  1232,  8139,    11, 14380,    11, 11904,\n",
       "            11,  5916,    11, 34101,    11,  9653,    11,  9891,    11, 32132,\n",
       "            11,  8887,    11,  6891,    11, 11311,    11,  8237,    11,  6099]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = model.generate(numeric_ids,max_length=500,num_beams=5,no_repeat_ngram_size=2,)\n",
    "result\n",
    "# no_repeat_ngram_size --> indicates no two gram matches that means no one match with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b364253b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I love watching motivational movies, and this one is one of my favorites. It\\'s about a guy who\\'s trying to lose weight, but he can\\'t seem to do it. So he goes to a weight loss clinic, where he meets a woman who says she can help him lose the weight.\\n\\nThe movie ends with the woman telling the guy that he\\'s not going to be able to keep his weight off forever. She tells him that if he wants to get healthy, he\\'ll have to change his eating habits. The guy says, \"I don\\'t know what you\\'re talking about. I\\'m not eating junk food.\" The woman then says that she\\'ll show him how to eat healthy and get rid of all the junk in his life. He says he doesn\\'t want to listen to her, so she walks away and leaves him to his own devices. That\\'s the end of the movie, right? Well, not so fast. There\\'s a lot more going on in this movie than meets the eye. Let\\'s take a closer look at what\\'s happening in the film.\\n\\n\\nFirst, let\\'s talk about the \"junk food\" part of this story. Junk food is food that\\'s high in calories and low in nutrients. For example, a bag of Cheetos is a high-calorie snack. But it\\'s also a low-nutrient snack, because it contains no vitamins, minerals, or fiber. In fact, the only thing it has in common with a healthy snack is that it comes in a plastic bag. If you eat it, you\\'ll end up with more calories than you started with, which means that you won\\'t be getting the nutrients you need to stay healthy. This is why junk foods are so bad for your health. They\\'re not good for you, they\\'re harmful to your body and you should avoid them at all costs. You can read more about this in my article on Junk Food and Weight Loss. Here\\'s another way to think about it: if you ate the same amount of food every day, it would take you a long time to burn off all of that food. Your body would have a hard time burning it all off, even though you\\'d have plenty of energy left over for other things, like exercising and eating more healthy foods like fruits, vegetables, whole grains, legumes, nuts, seeds, fish, poultry, eggs, cheese, yogurt, tea, coffee, chocolate, wine, beer'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(result[0],skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1d6a9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
